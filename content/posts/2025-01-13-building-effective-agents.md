---
title: "构建高效的智能体"
date: 2025-01-13
taxonomies:
  tags:
    - "Agent"
    - "AI"
extra:
  emoji: 🤖
---

> 近期 Anthropic 发布了一篇关于智能体系统的重要文章。他们预测 2025 年将是 Agentic 系统的关键年份,这个判断基于他们与众多行业团队合作开发 LLM 智能体的实践经验。
>
> 这篇综述文章总结了他们在构建 Agentic 系统过程中的关键发现和最佳实践。文章强调,成功的智能体实现往往采用简单、可组合的模式,而不是复杂的框架。对于想要开发智能体的团队来说,这是一份非常有价值的参考指南。
>
> 原文地址：https://www.anthropic.com/blog/building-efficient-agents

在过去一年中,我们与数十个跨行业团队合作构建大语言模型(LLM)智能体。我们发现,最成功的实现并非使用复杂的框架或专门的库,而是采用简单、可组合的模式进行构建。

在这篇文章中,我们分享了与客户合作和自主构建智能体过程中的经验,并为开发者提供构建高效智能体的实用建议。

## 什么是智能体?

"智能体"可以有多种定义。一些客户将智能体定义为能够长期独立运行、使用各种工具完成复杂任务的完全自主系统。另一些则用这个术语描述更具规范性的、遵循预定工作流程的实现。在 Anthropic,我们将所有这些变体都归类为**智能系统**,但在架构上区分**工作流**和**智能体**:

- **工作流**是通过预定义的代码路径来编排 LLM 和工具的系统。
- **智能体**则是 LLM 能够动态指导自身流程和工具使用的系统,可以控制如何完成任务。

下文我们将详细探讨这两种智能系统。在附录 1("实践中的智能体")中,我们描述了客户在使用这些系统时发现特别有价值的两个领域。

## 何时(以及何时不)使用智能体

在构建 LLM 应用时,我们建议寻找最简单的解决方案,只在必要时增加复杂性。这可能意味着完全不构建智能系统。智能系统通常会用延迟和成本来换取更好的任务表现,你需要考虑这种权衡是否合理。

当需要更多复杂性时,工作流为定义明确的任务提供可预测性和一致性,而智能体则在需要灵活性和模型驱动决策的规模化场景中更为适用。然而,对于许多应用来说,通过检索和上下文示例优化单个 LLM 调用通常就足够了。

## 何时以及如何使用框架

有许多框架可以让智能系统的实现变得更容易,包括:

- LangChain 的 [LangGraph](https://langchain-ai.github.io/langgraph/);
- Amazon Bedrock 的 [AI Agent framework](https://aws.amazon.com/bedrock/agents/);
- [Rivet](https://rivet.ironcladapp.com/),一个拖放式 GUI LLM 工作流构建器;
- [Vellum](https://www.vellum.ai/),另一个用于构建和测试复杂工作流的 GUI 工具。

这些框架通过简化标准的底层任务(如调用 LLM、定义和解析工具、链接调用等)使入门变得容易。但是,它们往往会创建额外的抽象层,掩盖底层的提示和响应,使调试变得更困难。它们也可能诱使开发者在更简单的设置就足够的情况下增加复杂性。

我们建议开发者从直接使用 LLM API 开始:许多模式只需几行代码就能实现。如果你确实使用框架,请确保理解底层代码。对底层实现的错误假设是客户常见的错误来源。

可以参考我们的[cookbook](https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents)获取一些示例实现。

## 构建模块、工作流和智能体

在本节中,我们将探讨生产环境中常见的智能系统模式。我们将从基础构建模块——增强型 LLM 开始,逐步增加复杂性,从简单的组合工作流到自主智能体。

### 构建模块:增强型 LLM

智能系统的基本构建模块是经过检索、工具和记忆等功能增强的 LLM。我们当前的模型可以主动使用这些功能——生成自己的搜索查询、选择适当的工具,并确定需要保留哪些信息。

![The augmented LLM](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fd3083d3f40bb2b6f477901cc9a240738d3dd1371-2401x1000.png&w=3840&q=75)

我们建议关注实现的两个关键方面:根据具体用例定制这些功能,并确保它们为 LLM 提供简单、文档完善的接口。虽然有多种方式实现这些增强功能,一种方法是通过我们最近发布的[模型上下文协议](https://www.anthropic.com/news/model-context-protocol),它允许开发者通过简单的[客户端实现](https://modelcontextprotocol.io/tutorials/building-a-client#building-mcp-clients)与不断增长的第三方工具生态系统集成。

在本文的其余部分,我们假设每个 LLM 调用都能访问这些增强功能。

### 工作流:提示链

提示链将任务分解为一系列步骤,每个 LLM 调用处理前一个调用的输出。你可以在任何中间步骤添加程序化检查(见下图中的"gate"),以确保流程仍在正轨上。

![The prompt chaining workflow](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7418719e3dab222dccb379b8879e1dc08ad34c78-2401x1000.png&w=3840&q=75)

**何时使用此工作流:** 当任务可以轻松清晰地分解为固定子任务时,这种工作流最为理想。主要目标是通过让每个 LLM 调用成为更简单的任务来用延迟换取更高的准确性。

**提示链有用的示例:**
- 生成营销文案,然后将其翻译成不同语言。
- 写一份文档大纲,检查大纲是否符合特定标准,然后基于大纲写文档。

### 工作流:路由

路由对输入进行分类并将其引导到专门的后续任务。这种工作流允许关注点分离,并构建更专门化的提示。如果没有这种工作流,为一种输入优化可能会损害对其他输入的性能。

![The routing workflow](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F5c0c0e9fe4def0b584c04d37849941da55e5e71c-2401x1000.png&w=3840&q=75)

**何时使用此工作流:** 当复杂任务有明显的不同类别需要分别处理,且分类可以由 LLM 或更传统的分类模型/算法准确处理时,路由效果很好。

**路由有用的示例:**
- 将不同类型的客服查询(一般问题、退款请求、技术支持)引导到不同的下游流程、提示和工具。
- 将简单/常见问题路由到 Claude 3.5 Haiku 等较小模型,将困难/不寻常问题路由到 Claude 3.5 Sonnet 等更强大的模型,以优化成本和速度。

### 工作流:并行化

LLM 有时可以同时处理任务,其输出通过程序化方式聚合。这种工作流——并行化有两个主要变体:
- **分段**: 将任务分解为并行运行的独立子任务。
- **投票:** 多次运行相同任务以获得多样化输出。

![The parallelization workflow](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F406bb032ca007fd1624f261af717d70e6ca86286-2401x1000.png&w=3840&q=75)

**何时使用此工作流:** 当任务可以并行化以提高速度,或需要多个视角/尝试来获得更高置信度的结果时,并行化是有效的。对于需要考虑多个方面的复杂任务,LLM 通常在每个考虑点由单独的 LLM 调用处理时表现更好,这允许对每个具体方面进行专注关注。

**并行化有用的示例:**

- **分段**:
  - 实现防护机制,一个模型实例处理用户查询,而另一个筛查不当内容或请求。这比让同一个 LLM 调用同时处理防护和核心响应表现更好。
  - 自动化评估 LLM 性能,每个 LLM 调用评估模型在给定提示下的不同方面表现。
- **投票**:
  - 审查代码中的漏洞,多个提示审查并在发现问题时标记代码。
  - 评估给定内容是否不当,多个提示评估不同方面或要求不同投票阈值来平衡误报和漏报。

### 工作流:编排者-工作者

在编排者-工作者工作流中,一个中央 LLM 动态分解任务,将其委派给工作者 LLM,并综合他们的结果。

![The orchestrator-workers workflow](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F8985fc683fae4780fb34eab1365ab78c7e51bc8e-2401x1000.png&w=3840&q=75)

**何时使用此工作流:** 这种工作流非常适合无法预测所需子任务的复杂任务(例如在编码中,需要更改的文件数量和每个文件中更改的性质可能取决于具体任务)。虽然在拓扑结构上与并行化类似,但关键区别在于其灵活性——子任务不是预定义的,而是由编排者根据具体输入确定的。

**编排者-工作者有用的示例:**
- 对多个文件进行复杂更改的编码产品。
- 涉及从多个来源收集和分析可能相关信息的搜索任务。

### 工作流:评估者-优化者

在评估者-优化者工作流中,一个 LLM 调用生成响应,而另一个在循环中提供评估和反馈。

![The evaluator-optimizer workflow](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F14f51e6406ccb29e695da48b17017e899a6119c7-2401x1000.png&w=3840&q=75)

**何时使用此工作流:** 当我们有明确的评估标准,且迭代改进能提供可衡量的价值时,这种工作流特别有效。判断是否适合的两个标志是:首先,当人类表达反馈时,LLM 响应可以得到明显改进;其次,LLM 能够提供这样的反馈。这类似于人类作者在创作精炼文档时可能经历的迭代写作过程。

**评估者-优化者有用的示例:**
- 文学翻译,其中有一些译者 LLM 最初可能无法捕捉的细微差别,但评估者 LLM 可以提供有用的批评。
- 需要多轮搜索和分析以收集全面信息的复杂搜索任务,评估者决定是否需要进一步搜索。

### 智能体

随着 LLM 在关键能力上日趋成熟——理解复杂输入、进行推理和规划、可靠地使用工具以及从错误中恢复,智能体正在生产环境中崭露头角。智能体通过与人类用户的命令或交互对话开始工作。一旦任务明确,智能体就会独立规划和运作,必要时会向人类寻求更多信息或判断。在执行过程中,智能体必须在每个步骤从环境中获取"基准事实"(如工具调用结果或代码执行)以评估其进展。智能体可以在检查点或遇到障碍时暂停以获取人类反馈。任务通常在完成时终止,但也常常包含停止条件(如最大迭代次数)以保持控制。

智能体可以处理复杂的任务,但其实现往往很简单。它们通常只是基于环境反馈在循环中使用工具的 LLM。因此,清晰周到地设计工具集及其文档至关重要。我们在附录 2("工具的提示工程")中详细阐述了工具开发的最佳实践。

![Autonomous agent](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F58d9f10c985c4eb5d53798dea315f7bb5ab6249e-2401x1000.png&w=3840&q=75)

**何时使用智能体:** 智能体适用于难以或无法预测所需步骤数量、且无法硬编码固定路径的开放性问题。LLM 可能需要多轮操作,你必须对其决策有一定程度的信任。智能体的自主性使其非常适合在可信环境中扩展任务。

智能体的自主性意味着更高的成本,以及错误累积的可能性。我们建议在沙盒环境中进行广泛测试,并配备适当的防护措施。

**智能体有用的示例:**

以下示例来自我们自己的实现:
- 一个用于解决 [SWE-bench 任务](https://www.anthropic.com/research/swe-bench-sonnet)的编码智能体,根据任务描述对多个文件进行编辑;
- 我们的["计算机使用"参考实现](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo),让 Claude 使用计算机完成任务。

![High-level flow of a coding agent](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F4b9a1f4eb63d5962a6e1746ac26bbc857cf3474f-2400x1666.png&w=3840&q=75)

## 组合和定制这些模式

这些构建模块并非强制性的。它们是开发者可以根据不同用例塑造和组合的常见模式。与任何 LLM 功能一样,成功的关键在于衡量性能并迭代实现。重申一点:只有在明确能改善结果时,才应考虑增加复杂性。

## 总结

在 LLM 领域,成功不在于构建最复杂的系统,而在于构建适合你需求的正确系统。从简单的提示开始,通过全面评估优化它们,只有在更简单的解决方案不足时才添加多步骤智能系统。

在实现智能体时,我们尽量遵循三个核心原则:

1. 保持智能体设计的**简单性**。
2. 通过明确展示智能体的规划步骤来优先考虑**透明性**。
3. 通过全面的工具**文档和测试**来精心打造智能体-计算机接口(ACI)。

框架可以帮助你快速入门,但在转向生产环境时,不要犹豫减少抽象层并使用基本组件构建。遵循这些原则,你可以创建不仅强大,而且可靠、可维护且受用户信任的智能体。

### 致谢

作者:Erik Schluntz 和 Barry Zhang。本文借鉴了我们在 Anthropic 构建智能体的经验,以及客户分享的宝贵见解,对此我们深表感谢。

## 附录 1: 智能体的实践应用

我们与客户的合作揭示了两个特别有前景的 AI 智能体应用场景,它们展示了上述模式的实际价值。这两个应用都说明了智能体在以下任务中最能发挥价值:需要对话和行动的结合、有明确的成功标准、能够形成反馈循环,并且包含有意义的人类监督。

### A. 客户支持

客户支持将熟悉的聊天机器人界面与通过工具集成实现的增强功能相结合。这非常适合更开放式的智能体,原因如下:

- 支持互动自然地遵循对话流程,同时需要访问外部信息和执行操作;
- 可以集成工具来获取客户数据、订单历史和知识库文章;
- 可以通过程序化方式处理退款或更新工单等操作;
- 可以通过用户定义的解决方案清晰地衡量成功。

几家公司通过基于使用量的定价模式证明了这种方法的可行性,他们只对成功解决的案例收费,这显示了他们对智能体效能的信心。

### B. 编码智能体

软件开发领域展现了 LLM 功能的巨大潜力,从代码补全发展到自主问题解决。智能体在这里特别有效,因为:

- 代码解决方案可以通过自动化测试进行验证;
- 智能体可以使用测试结果作为反馈来迭代解决方案;
- 问题空间定义明确且结构化;
- 输出质量可以客观衡量。

在我们自己的实现中,智能体现在可以仅基于拉取请求描述来解决 [SWE-bench Verified](https://www.anthropic.com/research/swe-bench-sonnet) 基准测试中的真实 GitHub 问题。然而,虽然自动化测试有助于验证功能,但人工审查对于确保解决方案符合更广泛的系统要求仍然至关重要。

## 附录 2: 工具的提示工程

无论你构建的是哪种智能系统,工具很可能都是你的智能体的重要组成部分。[工具](https://www.anthropic.com/news/tool-use-ga)使 Claude 能够通过在我们的 API 中指定其确切结构和定义来与外部服务和 API 交互。当 Claude 响应时,如果它计划调用工具,API 响应中会包含一个[工具使用块](https://docs.anthropic.com/en/docs/build-with-claude/tool-use#example-api-response-with-a-tool-use-content-block)。工具定义和规范应该得到与整体提示同等的提示工程关注。在这个简短的附录中,我们将描述如何对工具进行提示工程。

通常有几种方式可以指定相同的操作。例如,你可以通过编写差异或重写整个文件来指定文件编辑。对于结构化输出,你可以在 markdown 或 JSON 内返回代码。在软件工程中,这些差异是表面的,可以无损地从一种格式转换为另一种格式。然而,某些格式对 LLM 来说比其他格式更难编写。编写差异需要在写入新代码之前知道块头中有多少行在变化。在 JSON 中编写代码(相比 markdown)需要额外转义换行符和引号。

我们对决定工具格式的建议如下:

- 给模型足够的标记来"思考",避免它把自己写入死角。
- 保持格式接近模型在互联网上自然出现的文本。
- 确保没有格式"开销",比如必须保持对数千行代码的准确计数,或对它写的任何代码进行字符串转义。

一个经验法则是思考在人机界面(HCI)上投入了多少努力,并计划在创建良好的_智能体_-计算机界面(ACI)上投入同样多的努力。以下是一些实现方法:

- 站在模型的角度思考。基于描述和参数,使用这个工具是否显而易见,还是需要仔细思考?如果是后者,那么对模型来说可能也是如此。一个好的工具定义通常包括使用示例、边缘情况、输入格式要求,以及与其他工具的明确界限。
- 如何更改参数名称或描述以使事情更明显?把这想象成为团队中的初级开发人员写一个很棒的文档字符串。这在使用多个相似工具时尤其重要。
- 测试模型如何使用你的工具:在我们的[工作台](https://console.anthropic.com/workbench)中运行多个示例输入,看看模型会犯什么错误,并进行迭代。
- 对你的工具进行[防错](https://en.wikipedia.org/wiki/Poka-yoke)设计。更改参数使其更难出错。

在构建我们的 [SWE-bench](https://www.anthropic.com/research/swe-bench-sonnet) 智能体时,我们实际上花在优化工具上的时间比优化整体提示的时间还多。例如,我们发现当智能体移出根目录后,模型在使用相对文件路径的工具时会出错。为了解决这个问题,我们更改了工具,始终要求使用绝对文件路径——我们发现模型完美地使用了这种方法。
